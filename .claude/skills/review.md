# 代码审查 (Review)

在代码修改后进行全面审查，评估框架合理性、代码质量、可复用性和规范性。

## 职责

作为代码审查者，在每次重要代码修改后执行审查，确保代码质量和架构一致性。

## 审查维度

### 1. 框架合理性 (Architecture)

检查项目架构是否合理：

- [ ] **模块划分**: 各模块职责是否清晰单一
- [ ] **依赖关系**: 模块间依赖是否合理，有无循环依赖
- [ ] **数据流**: 数据流向是否清晰，是否符合管道设计
- [ ] **配置管理**: 配置是否集中管理，是否易于调整
- [ ] **扩展性**: 新增策略/功能是否容易扩展

```
期望架构:
pipeline/           → 数据处理（清洗、特征、校验）
src/lstm/           → 模型训练和实验
  ├── config.py     → 集中配置
  ├── models/       → 模型定义
  ├── experiments/  → 实验框架
  └── optimization/ → 优化工具
scripts/            → 运行脚本
```

### 2. 代码实现 (Implementation)

评估代码实现质量：

- [ ] **正确性**: 逻辑是否正确，边界条件是否处理
- [ ] **健壮性**: 异常处理是否完善，输入校验是否充分
- [ ] **效率**: 是否有性能瓶颈，大数据处理是否优化
- [ ] **可读性**: 代码是否清晰易懂，命名是否准确
- [ ] **时间序列安全**: 是否存在前瞻偏差风险

### 3. 可复用性 (Reusability)

检查代码复用设计：

- [ ] **DRY原则**: 是否有重复代码需要抽象
- [ ] **通用组件**: 工具函数是否放在 `shared/` 模块
- [ ] **配置参数化**: 硬编码值是否提取为配置
- [ ] **接口设计**: 函数/类接口是否通用且稳定

### 4. 规范性 (Standards)

验证代码规范遵守情况：

- [ ] **命名规范**:
  - 类名: `PascalCase` (如 `ExpandingWindowExecutor`)
  - 函数/变量: `snake_case` (如 `calculate_metrics`)
  - 常量: `UPPER_CASE` (如 `TRADING_CONFIG`)
- [ ] **类型注解**: 函数是否有类型提示
- [ ] **文档字符串**: 公共函数/类是否有 docstring
- [ ] **导入顺序**: 标准库 → 第三方库 → 本地模块
- [ ] **文件组织**: 文件是否放在正确的目录

### 5. 项目特定规范

本项目的特殊要求：

- [ ] **数据源只读**: 绝不修改 NAS 数据源
- [ ] **Walk-Forward**: 训练/测试严格按时间分离
- [ ] **配置集中**: LSTM 配置在 `src/lstm/config.py`
- [ ] **缓存清理**: 修改数据逻辑后提醒清除缓存
- [ ] **中文交流**: 所有输出和文档使用中文

## 审查流程

### 执行审查

```bash
# 触发代码审查
/review

# 审查特定文件
/review --files src/lstm/config.py

# 审查特定模块
/review --module optimization
```

### 审查报告格式

```markdown
# 代码审查报告

**审查时间**: 2026-01-17
**审查范围**: [修改的文件/模块]

## 审查结果

### 通过项 ✅
- [列出符合规范的项目]

### 待改进 ⚠️
- [优先级: 高/中/低] [问题描述] → [建议修改]

### 严重问题 ❌
- [必须修复的问题]

## 建议的修改

### 1. [问题标题]
**文件**: `path/to/file.py:123`
**问题**: [具体描述]
**建议**:
\`\`\`python
# 修改前
old_code

# 修改后
new_code
\`\`\`

## 总结
[整体评价和下一步建议]
```

## 常见问题和建议

### 框架问题

| 问题 | 建议 |
|------|------|
| 配置散落在多个文件 | 集中到 `config.py` |
| 重复的数据加载代码 | 抽象到 `BaseStrategyExecutor` |
| 硬编码的路径 | 使用配置常量 |
| 循环导入 | 重新组织模块结构 |

### 代码问题

| 问题 | 建议 |
|------|------|
| 缺少类型注解 | 添加 `-> ReturnType` |
| 过长的函数 | 拆分为小函数 |
| 魔法数字 | 提取为常量 |
| 裸 except | 指定具体异常类型 |
| 未使用的导入 | 删除或注释原因 |

### 时间序列问题

| 问题 | 建议 |
|------|------|
| 使用未来数据 | 检查特征计算时间点 |
| 随机划分数据 | 改用时间序列划分 |
| 标准化参数泄露 | 只用训练集计算 |

## 自动化检查（可选）

如果项目配置了 pre-commit hooks，可以自动检查：

```yaml
# .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: type-check
        name: Type Check
        entry: mypy src/
        language: system
        pass_filenames: false
      - id: lint
        name: Lint
        entry: ruff check src/
        language: system
        pass_filenames: false
```

## 审查优先级

1. **P0 - 必须修复**:
   - 前瞻偏差
   - 数据泄露
   - 安全漏洞

2. **P1 - 应该修复**:
   - 性能问题
   - 错误处理缺失
   - 接口不一致

3. **P2 - 建议改进**:
   - 代码风格
   - 文档完善
   - 测试覆盖

## 与其他 Skill 的关系

review skill 应在以下情况触发：

- `/clean` 完成后 → 检查数据处理逻辑
- `/train` 完成后 → 检查训练流程
- `/backtest` 完成后 → 检查回测逻辑
- `/archive` 之前 → 确保代码质量达标

## 输出

审查完成后生成：

- **终端输出**: 审查摘要和关键问题
- **详细报告**: `.claude/review_reports/{timestamp}.md`（如需保存）

## 下一步

审查完成后：

1. 如有 P0 问题，立即修复
2. P1 问题计划修复
3. P2 问题记录到 TODO
4. 审查通过后可继续下一步工作
